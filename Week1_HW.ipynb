{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "237a20e019714502ae566263f5d25bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6cad2dec9c54f73864150ee23814373",
              "IPY_MODEL_24ba0bde1b8847acaf5dd9c4d51d12ee"
            ],
            "layout": "IPY_MODEL_505d18cd702245679036c0da801f63d2"
          }
        },
        "f6cad2dec9c54f73864150ee23814373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe62cc002c74bfa885c0d8c5ecf8276",
            "placeholder": "​",
            "style": "IPY_MODEL_9e5f03e95c2b4455af75a49fa0e3402d",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "24ba0bde1b8847acaf5dd9c4d51d12ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f36d4cbf9034248981e6cee07496b5b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_268a92e4013740bba210c576db15a0aa",
            "value": 1
          }
        },
        "505d18cd702245679036c0da801f63d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe62cc002c74bfa885c0d8c5ecf8276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5f03e95c2b4455af75a49fa0e3402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f36d4cbf9034248981e6cee07496b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268a92e4013740bba210c576db15a0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41414ba788894e01bcf19e578e3fb2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00be6ab1a2504603b3bc9bde993f76fe",
              "IPY_MODEL_efbec1ec7cc247a18fcd82fd9bbe69a6"
            ],
            "layout": "IPY_MODEL_c8d67806077f4d609007305f23be2425"
          }
        },
        "00be6ab1a2504603b3bc9bde993f76fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a99084a0be242d2ab98bf3fa73f504a",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa4ee62db054a5b81adf03ea492e4f2",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "efbec1ec7cc247a18fcd82fd9bbe69a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5668ec2f8548cb83aa9d84547fe793",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39221bed229048bf83c41173458e3c56",
            "value": 1
          }
        },
        "c8d67806077f4d609007305f23be2425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a99084a0be242d2ab98bf3fa73f504a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa4ee62db054a5b81adf03ea492e4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a5668ec2f8548cb83aa9d84547fe793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39221bed229048bf83c41173458e3c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdonggyu2008/deep_daiv_-/blob/main/Week1_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 들어가며"
      ],
      "metadata": {
        "id": "ED-Vl68A8q8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "딥러닝을 공부할 때에는 논문을 읽고 이해하는 것도 중요하나 논문에 나온 아이디어를 실제로 구현할 수 있는 것도 중요합니다. 아이디어들은 많은 경우 수학, 통계학적 직관에서 출발하나 딥러닝 연구는 지극히 경험적 (Empirical)입니다. 앞으로 진행할 과제들은 매주 코딩을 간단히 수행하게 되는데, 데이터 수집부터 모델 제작, 학습 및 추론에 이르기까지 전 과정을 매주 구현하는 것은 무리가 있기에 전체 과정을 몇 단계로 나누고 이들 중 일부를 직접 구현해야 합니다. 딥러닝 모델링과 관련한 코딩 단계를 다음과 같이 나누어 보았습니다.\n",
        "\n",
        "---\n",
        "1.   **데이터 수집 및 전처리**\n",
        "\n",
        "먼저 모델 학습에 사용할 데이터를 수집합니다. 데이터는 주로 선행 연구에서 사용한 것을 이용하는 경우가 많으며 상황에 따라 새로운 데이터셋을 탐색할 수도 있습니다. 이후 모델링에 알맞은 방식으로 데이터를 전처리합니다. 정규화나 표준화를 이용할 수도 있으며, 패딩 (padding), 결측치 처리 (imputation), MFCC, Mel 등과 같은 신호처리, 트리밍 (trimming)(자르기) 등 기법을 사용할 수 있습니다.\n",
        "\n",
        "---\n",
        "2.   **모델 디자인**\n",
        "\n",
        "가장 재미있는 부분입니다. (지극히 주관적) CNN, RNN 등부터 시작해서 FCN, Attention, Masking 등 여러 모델링 아이디어를 코드로 구현하는 과정입니다. 딥러닝 프레임워크에서 제공하는 다양한 tool을 활용할 수도, 고전적인 방식을 활용해 코딩할 수도 있습니다.\n",
        "\n",
        "---\n",
        "3. **모델 학습**\n",
        "\n",
        "역시 매우 중요한 부분입니다. 학습 에폭 (epoch), 배치 크기 (batch size) 등 각종 설정을 조율하는 것부터 목적 함수 (objective function)를 설정하고 최적화 방식을 설정할 수 있습니다. 더불어 Gradient Vanishing 을 해결하거나 과적합을 방지하는 아이디어를 제안할 수 있고 다중 GPU인 경우에 병렬학습을 고안할 수 있습니다. 모델 학습 과정에서 teacher-forcing, distillation 등 학습 방법을 제안할 수도 있습니다.\n",
        "\n",
        "\n",
        "---\n",
        "4. **추론 및 평가**\n",
        "\n",
        "추론은 모델에서 가장 중요한 부분 중 하나입니다. 결국 추론을 할 수 있어야 모델을 상용화하고 배포할 수 있습니다. 디코더 기반이라면 loop을 이용해 autoregressive 구조를 제안해야 할 것이며, 분류 모델이었다면 softmax를 hard label로 바꾸어 실제 라벨을 맵핑하는 과정 등이 그 예시입니다.\n",
        "\n",
        "평가를 위한 지표는 목적 함수와는 다를 수도 있습니다. 모델 성능을 평가하기 위해 시각화, 음성화 등을 이용할 수 있고, 중간 feature extraction을 평가하기 위해 t-SNE 등을 활용하기도 합니다. 사람들에게 설문조사를 통해 모델의 성능을 비교할 수도 있습니다. 또한 모델의 효율성을 평가하기 위해 MACs, FLOPs 등을 이용해 연산복잡도를 측정할 수도 있습니다.\n",
        "\n",
        "---\n",
        "\n",
        "5. **기타**\n",
        "\n",
        "위의 과정 이외에도 여타 라이브러리를 이용해 모델 학습을 효율화하거나 모델링을 더 쉽게 만드는 여러 방법을 제안할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "*과제의 많은 문제들은 정답이 없는 경우가 많습니다.*"
      ],
      "metadata": {
        "id": "pxX1mnbP8s3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW 1. Design a Model that does not need positional embedding in AST, compare performance with AST without pretraining."
      ],
      "metadata": {
        "id": "FwPUCWg9DUsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "과제 목표: 모델 디자인, 모델 학습, 모델 추론 코드를 작성할 수 있다."
      ],
      "metadata": {
        "id": "XbtBGQItDdXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW 2. Test if different ‘patchify’ system does help training process converge better in AST"
      ],
      "metadata": {
        "id": "CIlGP7v03cyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 제반 작업"
      ],
      "metadata": {
        "id": "ZGteOo1OEBwp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rhmaa2mq8b6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5163ea-16a2-4b95-afe0-fbd38f48eed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.13.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "drive.mount(\"/content/gdrive\")\n",
        "import sys\n",
        "!pip install fvcore #컴퓨터 비전용\n",
        "!pip install timm #이미지 모델이 포함된 라이브러리\n",
        "!pip install torchinfo #pytorch의 모델 요약정보를 출력할때 사용\n",
        "!pip install python_speech_features # 음성신호 처리에 필요한 기능들\n",
        "!pip install wget #웹에서 파일 가져오기\n",
        "output.clear()\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 513a1f0c050fa7f60a76b5232e904d8df397082e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGw3r1DLiUVn",
        "outputId": "bf27480c-67b3-4030-c888-af32aca0aef3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast\n",
        "import os\n",
        "import timm\n",
        "from timm.models.layers import to_2tuple,trunc_normal_\n",
        "import wget\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from python_speech_features import mfcc, logfbank\n",
        "import librosa\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from fvcore.nn import parameter_count_table\n",
        "from torchinfo import summary\n",
        "import pickle\n",
        "import einops\n",
        "import torch.autograd as autograd\n",
        "import wandb"
      ],
      "metadata": {
        "id": "uvbjHRkmEXO5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing(전처리)"
      ],
      "metadata": {
        "id": "diClIBdVE3Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data Description\n",
        "\n",
        "https://www.kaggle.com/c/freesound-audio-tagging/data\n",
        "\n",
        "다양한 악기, 동물소리, 사람 소리 등이 라벨과 함께 주어진 데이터\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QkSDpbjm9dVu",
        "outputId": "32964edf-edfa-471d-dc41-66b54d6faec7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nData Description\\n\\nhttps://www.kaggle.com/c/freesound-audio-tagging/data\\n\\n다양한 악기, 동물소리, 사람 소리 등이 라벨과 함께 주어진 데이터\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "엔벨롭 함수(게이트) - 임계치 이하 에너지는 무시하고 나머지만 남김\n"
      ],
      "metadata": {
        "id": "Hvr6psTvYgZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def envelope(y, rate, threshold): #각 마스크별 유효값 확인(게이트 함수)\n",
        "  mask = []\n",
        "  y = pd.Series(y).apply(np.abs)  # make y absolute value\n",
        "  y_mean = y.rolling(window = int((rate/10)), min_periods = 1, center = True).mean()#??\n",
        "  for mean in y_mean: #각 윈도우의 평균이 임계값이 넘는지 확인하고 추가\n",
        "    if mean > threshold:\n",
        "      mask.append(True)\n",
        "    else:\n",
        "      mask.append(False)\n",
        "\n",
        "  return mask\n",
        "\n",
        "\n",
        "def normalize_mel(S, min_level_db = -100): #정규화\n",
        "    return np.clip((S-min_level_db)/-min_level_db, 0,1)"
      ],
      "metadata": {
        "id": "tP--ct7e9Z1I"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "m_path = \"/content/gdrive/MyDrive/Audio Classification/audio_train\" # 수정\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/Audio Classification/real_df.csv\") # 수정\n",
        "df.set_index(\"fname\", inplace = True) #fname을 기준으로 인덱스 지정\n",
        "\n",
        "if len(os.listdir(\"/content/gdrive/MyDrive/Audio Classification/clean\")) == 0:\n",
        "  for f in tqdm(df.fname):#데이터프레임의 파일 이름별로 읽어옴\n",
        "    signal, rate = librosa.load(os.path.join(m_path, f), sr = 16000)\n",
        "    mask = envelope(signal, rate, 0.0005)\n",
        "    wavfile.write(filename = \"/content/gdrive/MyDrive/Audio Classification/clean/\"+f, rate = rate, data = signal[mask])\n",
        "#파일이름, 16000 샘플링레이트, 시그널 중 true인 값만 남긴 데이터로만 구성됨\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "waL_JqgEEoGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "5a848057-9237-4cee-8c1b-35abfe9bb0c6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nm_path = \"/content/gdrive/MyDrive/Audio Classification/audio_train\" # 수정\\ndf = pd.read_csv(\"/content/gdrive/MyDrive/Audio Classification/real_df.csv\") # 수정\\ndf.set_index(\"fname\", inplace = True) #fname을 기준으로 인덱스 지정\\n\\nif len(os.listdir(\"/content/gdrive/MyDrive/Audio Classification/clean\")) == 0:\\n  for f in tqdm(df.fname):#데이터프레임의 파일 이름별로 읽어옴\\n    signal, rate = librosa.load(os.path.join(m_path, f), sr = 16000)\\n    mask = envelope(signal, rate, 0.0005)\\n    wavfile.write(filename = \"/content/gdrive/MyDrive/Audio Classification/clean/\"+f, rate = rate, data = signal[mask])\\n#파일이름, 16000 샘플링레이트, 시그널 중 true인 값만 남긴 데이터로만 구성됨\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤으로 정해진 샘플의\n",
        "\n",
        "랜덤한 위치의 멜스펙트로그램과\n",
        "\n",
        "라벨을 npy파일로 저장함"
      ],
      "metadata": {
        "id": "ClD8WRB6a5Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "classes = df[\"label\"].unique() #안겹치게 라벨들 가져옴, numpy배열\n",
        "class_dist = df.groupby([\"label\"])[\"length\"].mean() #각 라벨별 길이평균, Mean duration for every class ex: saxophone = 3.2 ...\n",
        "n_samples = 3 * int(df[\"length\"].sum()/10)  # 샘플링 할 갯수 계산(?) how many times in sampling.\n",
        "prob_dist = class_dist/class_dist.sum() #각 라벨별 샘플링될 확률, sampling probability proportional to n_samples\n",
        "step = int(128*99) #약 0.7초용 스텝갯수 sampling for about 0.7 seconds.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aWE-IpjEd7FR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3202a610-4aed-416c-fe5c-fc7345049be1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclasses = df[\"label\"].unique() #안겹치게 라벨들 가져옴, numpy배열\\nclass_dist = df.groupby([\"label\"])[\"length\"].mean() #각 라벨별 길이평균, Mean duration for every class ex: saxophone = 3.2 ...\\nn_samples = 3 * int(df[\"length\"].sum()/10)  # 샘플링 할 갯수 계산(?) how many times in sampling.\\nprob_dist = class_dist/class_dist.sum() #각 라벨별 샘플링될 확률, sampling probability proportional to n_samples\\nstep = int(128*99) #약 0.7초용 스텝갯수 sampling for about 0.7 seconds.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def build_rand_feat():\n",
        "  random.seed(1229)\n",
        "  X = []\n",
        "  labels = []\n",
        "  _min, _max = float(\"inf\"), -float(\"inf\")# 최대 최소\n",
        "  for _ in tqdm(range(n_samples)):#샘플 갯수 만큼 반복\n",
        "    rand_class = np.random.choice(class_dist.index, p = prob_dist) #랜덤하게 하나 가져옴\n",
        "    file = np.random.choice(df[df.label == rand_class].index)  # RandomSample a file in the class category\n",
        "    try: #랜덤한 샘플 가져오기\n",
        "\n",
        "      wav, sr = librosa.load(\"/content/gdrive/MyDrive/Audio Classification/clean/\"+file, sr = 16000)\n",
        "      #가져와지는 wav는 numpy2차원 배열\n",
        "      label = str(df.at[file, \"label\"]) # sampled instrument\n",
        "    except:\n",
        "      print(\"can't read file; moving onto next file\")\n",
        "      continue\n",
        "    try:#랜덤한 샘플의 랜덤한 위치 가져오기\n",
        "\n",
        "      rand_index = np.random.randint(0, wav.shape[0]-step)# 스텝이 int라 위치도 int로 가져옴\n",
        "      sample = wav[rand_index:rand_index+step] # sample for about 0.7 seconds\n",
        "\n",
        "      X_sample = librosa.feature.melspectrogram(y = sample, sr = sr, n_fft = 1024, hop_length = 128, n_mels = 128)#데이터 추출\n",
        "      X_sample = normalize_mel(librosa.power_to_db(X_sample, ref = np.max)) # 파워 멜스펙트로그램 Normalized Log Mel Spectrogram\n",
        "      X.append(X_sample)\n",
        "      label = np.where(classes == label)[0][0]\n",
        "      labels.append(label)\n",
        "\n",
        "    except:\n",
        "\n",
        "      continue\n",
        "\n",
        "  return X, labels\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "IT1VFXL59q5W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "ad730638-a395-45bb-97f5-4ec5d59eb955"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef build_rand_feat():\\n  random.seed(1229)\\n  X = []\\n  labels = []\\n  _min, _max = float(\"inf\"), -float(\"inf\")# 최대 최소\\n  for _ in tqdm(range(n_samples)):#샘플 갯수 만큼 반복\\n    rand_class = np.random.choice(class_dist.index, p = prob_dist) #랜덤하게 하나 가져옴\\n    file = np.random.choice(df[df.label == rand_class].index)  # RandomSample a file in the class category\\n    try: #랜덤한 샘플 가져오기\\n\\n      wav, sr = librosa.load(\"/content/gdrive/MyDrive/Audio Classification/clean/\"+file, sr = 16000)\\n      #가져와지는 wav는 numpy2차원 배열\\n      label = str(df.at[file, \"label\"]) # sampled instrument\\n    except:\\n      print(\"can\\'t read file; moving onto next file\")\\n      continue\\n    try:#랜덤한 샘플의 랜덤한 위치 가져오기\\n\\n      rand_index = np.random.randint(0, wav.shape[0]-step)# 스텝이 int라 위치도 int로 가져옴\\n      sample = wav[rand_index:rand_index+step] # sample for about 0.7 seconds\\n\\n      X_sample = librosa.feature.melspectrogram(y = sample, sr = sr, n_fft = 1024, hop_length = 128, n_mels = 128)#데이터 추출\\n      X_sample = normalize_mel(librosa.power_to_db(X_sample, ref = np.max)) # 파워 멜스펙트로그램 Normalized Log Mel Spectrogram\\n      X.append(X_sample)\\n      label = np.where(classes == label)[0][0]\\n      labels.append(label)\\n\\n    except:\\n\\n      continue\\n\\n  return X, labels\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "X, y = build_rand_feat() #랜덤한 요소 멜스펙트로그램, 라벨 저장\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "np.save(\"/content/gdrive/MyDrive/코딩공부/deep_daiv/dataset/Xmel_torch.npy\", X)\n",
        "np.save(\"/content/gdrive/MyDrive/코딩공부/deep_daiv/dataset/ymel_torch.npy\", y)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "deSJ4ogI-4IY",
        "outputId": "771ac3b9-2a43-4c1b-bd47-cf4760d88229"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX, y = build_rand_feat() #랜덤한 요소 멜스펙트로그램, 라벨 저장\\nX = np.array(X)\\ny = np.array(y)\\n\\nnp.save(\"/content/gdrive/MyDrive/코딩공부/deep_daiv/dataset/Xmel_torch.npy\", X)\\nnp.save(\"/content/gdrive/MyDrive/코딩공부/deep_daiv/dataset/ymel_torch.npy\", y)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "Oob9zxtiOeU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "m16S-d31aAkK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정 필요\n",
        "\n",
        "X = np.load(\"/content/gdrive/MyDrive/코딩공부/deep_daiv/dataset/Xmel_torch.npy\", allow_pickle = True) # 데이터 수, 멜주파수 대역 갯수, 시간축 길이(#data, #mel_bins, #time bins)\n",
        "y = np.load(\"/content/gdrive/MyDrive/코딩공부/deep_daiv/dataset/ymel_torch.npy\") # 각 파일의 라벨(#data, )"
      ],
      "metadata": {
        "id": "NZQnRxqoOgKV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 라벨에 대해서 원핫 인코딩\n",
        "\n",
        "해당 인코딩을 통해"
      ],
      "metadata": {
        "id": "Yx9uk74GctD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 41\n",
        "\n",
        "y = np.eye(num_classes)[y] # 각 데이터에 대해 대각행렬 적용, 한마디로 각각 1을 가지는 위치가 생김One-hot-encoder\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "#데이터 갯수, 멜스펙트로그램 대역 갯수, 시간축 길이(100으로 나눔)\n",
        "#데이터 갯수, 각 라벨에 대한 원핫 인코딩 값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEF3HE5afvNt",
        "outputId": "aadec700-3cee-49f1-8ecb-c2c63a559075"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16745, 128, 100) (16745, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "오디오 데이터셋 선언\n"
      ],
      "metadata": {
        "id": "jkI4RdyWdFpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class audio_dataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "\n",
        "        #데이터셋으로 묶음\n",
        "        self.X_data = X_data #(#data, #coefs, #timetsteps)\n",
        "        self.y_data = y_data #(#data, #labels)\n",
        "        #플로트 텐서화\n",
        "        self.X_torch = torch.FloatTensor(self.X_data).to(device) #(#data, #coefs, #timetsteps)\n",
        "        self.y_torch = torch.FloatTensor(self.y_data).to(device) #(#data, #labels)\n",
        "        #길이, 샘플 갯수 추출\n",
        "        self.x_len = self.X_torch.shape[0]\n",
        "        self.y_len = self.y_torch.shape[0]\n",
        "        #조건여부 확인\n",
        "        assert self.x_len == self.y_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_torch[index], self.y_torch[index] #x=인덱스값의 데이터, 주파수 대역, 시간 반환, y=인덱스 값의 데이터, 라벨 원핫 반환\n",
        "    def __len__(self): #데이터 갯수 반환\n",
        "        return self.x_len"
      ],
      "metadata": {
        "id": "7WbWw1VWGPTC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTI-HEAD-ATTENTION\n",
        "\n",
        "\n",
        "I\n",
        "\n",
        "\n",
        "V\n",
        "\n",
        "\n",
        "MLP, POOLING"
      ],
      "metadata": {
        "id": "UvWrBn9hub8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CIjeSkUEpjOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_model(model, input_shape, is_cuda = False): #모델 확인\n",
        "  global device\n",
        "\n",
        "  if is_cuda: #gpu여부 확인\n",
        "    x = torch.rand(input_shape).to(device)\n",
        "  else:\n",
        "    x = torch.rand(input_shape)\n",
        "  print(parameter_count_table(model))\n",
        "\n",
        "  print(summary(model, input_size = input_shape))"
      ],
      "metadata": {
        "id": "300deR4JeH0F"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "17LfQPsA9wFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  # [Batch_size, sequence_length, emb_size], 나눠진 데이터 값들, 각 데이터 길이,\n",
        "    def __init__(self, emb_size = 384, num_heads = 6, dropout = 0):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size #변형할 데이터의 차원\n",
        "        self.num_heads = num_heads #멀티헤드 어텐션의 헤드 수\n",
        "        # fuse the queries, keys and values in one matrix\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3) #[배치 사이즈, 시퀀스 길이, emb_size*3]형태\n",
        "        self.att_drop = nn.Dropout(dropout) #드롭아웃 지정\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #x.shape = [batch_size, num_patches, embed_dim]\n",
        "\n",
        "        # split keys, queries and values in num_heads\n",
        "        qkv = einops.rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
        "        #차원 형태 변경, [3,배치 사이즈, num_heads, 헤드 디멘션(6)]으로 변경\n",
        "        queries, keys, values = qkv[0], qkv[1], qkv[2] #각각 똑같은 형태의 차원으로 나눔\n",
        "        # sum up over the last axis\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
        "        #배치, 헤드, 쿼리, 헤드 차원 과 배치, 헤드, 키, 헤드 차원 -> 배치, 헤드, 쿼리길이,  키 길이\n",
        "        scaling = self.emb_size ** (1/2)\n",
        "        #어텐션 계산\n",
        "\n",
        "        att = F.softmax(energy / scaling, dim=-1)\n",
        "        att = self.att_drop(att)\n",
        "        # sum up over the third axis\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = einops.rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "indgeAa73zki"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pooling(nn.Module):\n",
        "  def __init__(self,pool_size=3):\n",
        "    super().__init__()\n",
        "    self.pool=nn.AvgPool2d(\n",
        "        pool_size,stride=1,padding=pool_size//2,count_include_pad=False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.pool(x)-x"
      ],
      "metadata": {
        "id": "3ipzWzKX8lk6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, emb_size=384, num_heads=8, dropout=0.1, forward_expansion=2,pool_size=3):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.norm1 = nn.LayerNorm(emb_size) #정규화 레이어 2개\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.token_mixer=Pooling(pool_size=pool_size) #수정부분\n",
        "        self.feed_forward = nn.Sequential( #순서 지정\n",
        "            nn.Linear(emb_size, forward_expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(forward_expansion * emb_size, emb_size),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x): #x는 배치사이즈, emb_size, 시퀸스 길이\n",
        "\n",
        "        x=+x+self.token_mixer(self.norm1(x)) #수정부분\n",
        "        x=x+self.feed_forward(self.norm2(x))\n",
        "\n",
        "        return x # Input shape and Output Shape are the same."
      ],
      "metadata": {
        "id": "907nt48_cDeV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AST(nn.Module):\n",
        "    \"\"\"\n",
        "    label_dim: the number of total classes, 41\n",
        "    fstride: the stride of patch spliting on the frequency dimension, int\n",
        "    tstride: the stride of patch spliting on the time dimension\n",
        "    input_fdim: # frequency bins of the input spectrogram\n",
        "    input_tdim: # time frames of the input spectrogram\n",
        "    embed_dim : # embed_dimensions of ViT\n",
        "    \"\"\"\n",
        "    def __init__(self, label_dim=41, fstride=10, tstride=10, input_fdim=128, input_tdim=100, embed_dim = 384, num_heads = 6, n_blocks = 12, verbose=True):\n",
        "\n",
        "        super(AST, self).__init__()\n",
        "\n",
        "        self.label_dim = label_dim\n",
        "        self.fstride = fstride\n",
        "        self.tstride = tstride\n",
        "        self.input_fdim = input_fdim\n",
        "        self.input_tdim = input_tdim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.n_blocks = n_blocks\n",
        "\n",
        "\n",
        "        if verbose == True:\n",
        "            print('---------------AST Model Initializing---------------')\n",
        "\n",
        "\n",
        "\n",
        "        self.patch_embedding = nn.Conv2d(in_channels = 1, out_channels = self.embed_dim, kernel_size = 16, stride = (self.fstride, self.tstride))\n",
        "        #주어진 범위를 클래스 토큰으로 지정\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embed_dim))\n",
        "        #모델로 사용할 텐서를 랜덤으로 지정\n",
        "        self.patch_embedding.apply(self.init_weights)\n",
        "\n",
        "        #가중치 추기화\n",
        "        f_dim, t_dim = self.get_shape(fstride = self.fstride, tstride = self.tstride,\n",
        "                       input_fdim = self.input_fdim, input_tdim = self.input_tdim)\n",
        "        num_patches = f_dim * t_dim\n",
        "        #입력 데이터 크기, 스트라이드 기반 패치 갯수 계산\n",
        "        #self.position_embeddings = nn.Parameter(torch.randn(num_patches + 1, self.embed_dim))\n",
        "\n",
        "\n",
        "        self.blocks = nn.ModuleList() # Transformer block 만들기.\n",
        "        for _ in range(self.n_blocks): #트랜스포머 블록 갯수만큼 돌기\n",
        "          self.blocks.append(TransformerBlock(self.embed_dim, self.num_heads)) #int,\n",
        "\n",
        "\n",
        "        self.norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.mlp_head = nn.Sequential(nn.LayerNorm(self.embed_dim), nn.Linear(self.embed_dim, self.label_dim))\n",
        "\n",
        "\n",
        "        if verbose == True:\n",
        "\n",
        "            print('frequency stride={:d}, time stride={:d}'.format(self.fstride, self.tstride))\n",
        "            print('number of patches={:d}'.format(num_patches))\n",
        "\n",
        "\n",
        "\n",
        "    def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=100):\n",
        "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
        "        test_proj = nn.Conv2d(1, self.embed_dim, kernel_size=16, stride=(fstride, tstride))\n",
        "        test_out = test_proj(test_input)\n",
        "        f_dim = test_out.shape[2]\n",
        "        t_dim = test_out.shape[3]\n",
        "        return f_dim, t_dim\n",
        "\n",
        "    def init_weights(self, m, mean = 0.0, std = 0.01):\n",
        "      classname = m.__class__.__name__\n",
        "      if classname.find(\"Conv\") != -1: # if module == Conv\n",
        "        m.weight.data.normal_(mean,std) #Initialize weights\n",
        "\n",
        "    @autocast() #Speed up Training\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: the input spectrogram, expected shape: (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n",
        "        return: prediction\n",
        "        \"\"\"\n",
        "        # expect input x = (batch_size, frequency bins, time bins), e.g., (16, 128, 100)\n",
        "        x = x.unsqueeze(1) # (batch_size, 1, frequency bins, time bins), e.g., (16, 1, 128, 100)\n",
        "\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embedding(x) # (batch_size, #embed_dim, f_dim, t_dim)\n",
        "        x = x.flatten(2) # (batch_size, #embed_dim, num_patches)\n",
        "        x = x.transpose(1, 2) #(batch_size, num_patches, #embed_dim)\n",
        "\n",
        "        #여긴 모양 동일?\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, #embed_dim)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)  # (B, num_patches + 1, #embed_dim)\n",
        "        #??\n",
        "        #x = x + self.position_embeddings #(B, num_patches + 1, #embed_dim)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = (x[:, 0] + x[:, 1]) / 2 # (B, 1, #embed dim).\n",
        "\n",
        "        x = self.mlp_head(x) # Why no Softmax in the end? https://slamwithme.oopy.io/305bb7e0-1062-4785-a82e-9e2a5debd0f4\n",
        "        #소프트맥스가 없네? 뭐로 구별하는거지\n",
        "        return x"
      ],
      "metadata": {
        "id": "eZVBjmwiby9J"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 M parameters\n",
        "\n",
        "ast = AST(num_heads = 3, n_blocks = 6).to(device)\n",
        "summarize_model(ast, [16, 100, 128], is_cuda = True) #[Batch_size, sequence_length, emb_size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKjMfZ0GeCkk",
        "outputId": "14828e18-d25f-44da-8238-ac407583d775"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------AST Model Initializing---------------\n",
            "frequency stride=10, time stride=10\n",
            "number of patches=108\n",
            "| name                     | #elements or shape   |\n",
            "|:-------------------------|:---------------------|\n",
            "| model                    | 3.7M                 |\n",
            "|  cls_token               |  (1, 1, 384)         |\n",
            "|  patch_embedding         |  98.7K               |\n",
            "|   patch_embedding.weight |   (384, 1, 16, 16)   |\n",
            "|   patch_embedding.bias   |   (384,)             |\n",
            "|  blocks                  |  3.6M                |\n",
            "|   blocks.0               |   0.6M               |\n",
            "|    blocks.0.norm1        |    0.8K              |\n",
            "|    blocks.0.norm2        |    0.8K              |\n",
            "|    blocks.0.feed_forward |    0.6M              |\n",
            "|   blocks.1               |   0.6M               |\n",
            "|    blocks.1.norm1        |    0.8K              |\n",
            "|    blocks.1.norm2        |    0.8K              |\n",
            "|    blocks.1.feed_forward |    0.6M              |\n",
            "|   blocks.2               |   0.6M               |\n",
            "|    blocks.2.norm1        |    0.8K              |\n",
            "|    blocks.2.norm2        |    0.8K              |\n",
            "|    blocks.2.feed_forward |    0.6M              |\n",
            "|   blocks.3               |   0.6M               |\n",
            "|    blocks.3.norm1        |    0.8K              |\n",
            "|    blocks.3.norm2        |    0.8K              |\n",
            "|    blocks.3.feed_forward |    0.6M              |\n",
            "|   blocks.4               |   0.6M               |\n",
            "|    blocks.4.norm1        |    0.8K              |\n",
            "|    blocks.4.norm2        |    0.8K              |\n",
            "|    blocks.4.feed_forward |    0.6M              |\n",
            "|   blocks.5               |   0.6M               |\n",
            "|    blocks.5.norm1        |    0.8K              |\n",
            "|    blocks.5.norm2        |    0.8K              |\n",
            "|    blocks.5.feed_forward |    0.6M              |\n",
            "|  norm                    |  0.8K                |\n",
            "|   norm.weight            |   (384,)             |\n",
            "|   norm.bias              |   (384,)             |\n",
            "|  mlp_head                |  16.6K               |\n",
            "|   mlp_head.0             |   0.8K               |\n",
            "|    mlp_head.0.weight     |    (384,)            |\n",
            "|    mlp_head.0.bias       |    (384,)            |\n",
            "|   mlp_head.1             |   15.8K              |\n",
            "|    mlp_head.1.weight     |    (41, 384)         |\n",
            "|    mlp_head.1.bias       |    (41,)             |\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "AST                                      [16, 41]                  384\n",
            "├─Conv2d: 1-1                            [16, 384, 9, 12]          98,688\n",
            "├─ModuleList: 1-2                        --                        --\n",
            "│    └─TransformerBlock: 2-1             [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-1               [16, 109, 384]            768\n",
            "│    │    └─Pooling: 3-2                 [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-3               [16, 109, 384]            768\n",
            "│    │    └─Sequential: 3-4              [16, 109, 384]            590,976\n",
            "│    └─TransformerBlock: 2-2             [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-5               [16, 109, 384]            768\n",
            "│    │    └─Pooling: 3-6                 [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-7               [16, 109, 384]            768\n",
            "│    │    └─Sequential: 3-8              [16, 109, 384]            590,976\n",
            "│    └─TransformerBlock: 2-3             [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-9               [16, 109, 384]            768\n",
            "│    │    └─Pooling: 3-10                [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-11              [16, 109, 384]            768\n",
            "│    │    └─Sequential: 3-12             [16, 109, 384]            590,976\n",
            "│    └─TransformerBlock: 2-4             [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-13              [16, 109, 384]            768\n",
            "│    │    └─Pooling: 3-14                [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-15              [16, 109, 384]            768\n",
            "│    │    └─Sequential: 3-16             [16, 109, 384]            590,976\n",
            "│    └─TransformerBlock: 2-5             [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-17              [16, 109, 384]            768\n",
            "│    │    └─Pooling: 3-18                [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-19              [16, 109, 384]            768\n",
            "│    │    └─Sequential: 3-20             [16, 109, 384]            590,976\n",
            "│    └─TransformerBlock: 2-6             [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-21              [16, 109, 384]            768\n",
            "│    │    └─Pooling: 3-22                [16, 109, 384]            --\n",
            "│    │    └─LayerNorm: 3-23              [16, 109, 384]            768\n",
            "│    │    └─Sequential: 3-24             [16, 109, 384]            590,976\n",
            "├─LayerNorm: 1-3                         [16, 109, 384]            768\n",
            "├─Sequential: 1-4                        [16, 41]                  --\n",
            "│    └─LayerNorm: 2-7                    [16, 384]                 768\n",
            "│    └─Linear: 2-8                       [16, 41]                  15,785\n",
            "==========================================================================================\n",
            "Total params: 3,671,465\n",
            "Trainable params: 3,671,465\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 227.69\n",
            "==========================================================================================\n",
            "Input size (MB): 0.82\n",
            "Forward/backward pass size (MB): 120.57\n",
            "Params size (MB): 14.68\n",
            "Estimated Total Size (MB): 136.08\n",
            "==========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "w7wNdbszOdQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'lr': 0.0002,\n",
        "    'epochs': 30,\n",
        "    'min_batch': 16,\n",
        "    'weight_decay': 1e-4, # optional, TBD\n",
        "    \"save_path\": \"/content/gdrive/MyDrive/코딩공부/deep_daiv/results\"\n",
        "}"
      ],
      "metadata": {
        "id": "A8N183NGWx4w"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_len = X.shape[0] #데이터 갯수\n",
        "train_size = 0.8 #학습데이터 비율\n",
        "idx = np.random.permutation(X_len) #데이터를 섞어서 학습, 테스트가 랜덤하게 선택됨\n",
        "#학습데이터, 테스트 데이터 인덱스\n",
        "train_idx = idx[:round(train_size*X_len)]; test_idx = idx[round(train_size*X_len):]\n",
        "#학습 데이터, 테스트 데이터를 인덱스에 따라 추출\n",
        "X_train = X[train_idx].astype(np.float32); X_test = X[test_idx].astype(np.float32);\n",
        "#골라진 학습데이터, 테스트 데이터의 레이블 추출\n",
        "y_train = y[train_idx].astype(np.float32); y_test = y[test_idx].astype(np.float32) ;\n",
        "\n",
        "#데이터셋, 레이블 묶음\n",
        "audio_train = audio_dataset(X_train, y_train)\n",
        "audio_test = audio_dataset(X_test, y_test)\n",
        "\n",
        "#묶인 데이터들 읽어옴\n",
        "train_loader = DataLoader(audio_train, batch_size = CONFIG[\"min_batch\"], shuffle = True)\n",
        "test_loader = DataLoader(audio_test, batch_size = CONFIG[\"min_batch\"], shuffle = True)"
      ],
      "metadata": {
        "id": "x8gZtb1rrysh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AST(num_heads = 3, n_blocks = 6).to(device)\n",
        "criterion = nn.CrossEntropyLoss() #크로스 엔트로피로 확인\n",
        "optimizer = optim.Adam(model.parameters(), lr = CONFIG[\"lr\"])\n",
        "\n",
        "loss_history = []\n",
        "val_loss_history = []\n",
        "init_loss = 991229 # Random high number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-_VmwhK35Po",
        "outputId": "77d803e1-bdc2-4d1c-9a8c-59dfcbe5c26a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------AST Model Initializing---------------\n",
            "frequency stride=10, time stride=10\n",
            "number of patches=108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"ast transformer\",\n",
        "    config={\n",
        "        \"learning_rate\":0.0002,\n",
        "        \"architecture\":\"transformer\",\n",
        "        \"dataset\":\"ast\",\n",
        "        \"epochs\":30,\n",
        "        'weight_decay': 1e-4,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "237a20e019714502ae566263f5d25bf4",
            "f6cad2dec9c54f73864150ee23814373",
            "24ba0bde1b8847acaf5dd9c4d51d12ee",
            "505d18cd702245679036c0da801f63d2",
            "cbe62cc002c74bfa885c0d8c5ecf8276",
            "9e5f03e95c2b4455af75a49fa0e3402d",
            "9f36d4cbf9034248981e6cee07496b5b",
            "268a92e4013740bba210c576db15a0aa"
          ]
        },
        "id": "KwmoCNHgjDTY",
        "outputId": "4fdb0b33-0849-4aef-b8c7-04e811f18187"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112563911112577, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "237a20e019714502ae566263f5d25bf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240819_120452-2puusksh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer/runs/2puusksh' target=\"_blank\">youthful-cosmos-10</a></strong> to <a href='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer' target=\"_blank\">https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer/runs/2puusksh' target=\"_blank\">https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer/runs/2puusksh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer/runs/2puusksh?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x78533a399660>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initializing training...\") #학습 시작\n",
        "torch.manual_seed(1229)\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(CONFIG[\"epochs\"])): #에폭 횟수만큼\n",
        "  print(f\"\\n Epoch {epoch}...\")\n",
        "  run_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader):\n",
        "\n",
        "    #학습 시퀀스\n",
        "    inputs, labels = data #샘플 갯수, 라벨 분리\n",
        "    optimizer.zero_grad() #초기화\n",
        "    outputs = model(inputs) #모델에 넣음\n",
        "\n",
        "    loss = criterion(outputs, labels)#확인\n",
        "\n",
        "    loss.backward()#역전파\n",
        "    optimizer.step()\n",
        "    run_loss += loss.item()\n",
        "\n",
        "\n",
        "    #평가 시퀀스\n",
        "    if i % 500 == 499: #1번이 붙은 횟수 마다 반복\n",
        "      loss_history.append(run_loss/500)\n",
        "      wandb.log({\"loss\": loss})\n",
        "      print(f'[{epoch +1}, {i + 1:5d}] loss : {run_loss/500:.3f}')\n",
        "      run_loss = 0.0\n",
        "\n",
        "      with torch.no_grad(): #그래디언트 계산 안함\n",
        "          val_loss = 0.0\n",
        "          for k, (val_inputs, val_labels) in enumerate(test_loader):\n",
        "              val_output = model(val_inputs)\n",
        "              v_loss = criterion(val_output, val_labels) #예측과 실제값 비교, 출력은 스칼라값\n",
        "              val_loss += v_loss\n",
        "          print(f'[{epoch + 1}, {i + 1:5d}] val loss: {val_loss / k:.3f}')\n",
        "          wandb.log({\"val loss\": val_loss})\n",
        "          val_loss_history.append(val_loss.item()/500)\n",
        "\n",
        "      if val_loss < init_loss: #더 좋으면 업데이트\n",
        "          torch.save(model, os.path.join(CONFIG[\"save_path\"], 'ast.pt'))\n",
        "\n",
        "          init_loss = val_loss\n",
        "wandb.finish()\n",
        "print(\"finished training ...\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "41414ba788894e01bcf19e578e3fb2c2",
            "00be6ab1a2504603b3bc9bde993f76fe",
            "efbec1ec7cc247a18fcd82fd9bbe69a6",
            "c8d67806077f4d609007305f23be2425",
            "2a99084a0be242d2ab98bf3fa73f504a",
            "6fa4ee62db054a5b81adf03ea492e4f2",
            "2a5668ec2f8548cb83aa9d84547fe793",
            "39221bed229048bf83c41173458e3c56"
          ]
        },
        "id": "3SR7yxUY41wN",
        "outputId": "ab1a6ab2-f8c3-4b61-f2ff-ce815b9c02c1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 0...\n",
            "[1,   500] loss : 3.433\n",
            "[1,   500] val loss: 3.304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/30 [00:12<06:16, 12.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1...\n",
            "[2,   500] loss : 3.171\n",
            "[2,   500] val loss: 3.042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [00:23<05:21, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 2...\n",
            "[3,   500] loss : 2.993\n",
            "[3,   500] val loss: 3.074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:33<04:50, 10.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 3...\n",
            "[4,   500] loss : 2.905\n",
            "[4,   500] val loss: 2.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [00:43<04:30, 10.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 4...\n",
            "[5,   500] loss : 2.832\n",
            "[5,   500] val loss: 2.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [00:53<04:18, 10.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 5...\n",
            "[6,   500] loss : 2.800\n",
            "[6,   500] val loss: 2.790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [01:03<04:08, 10.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 6...\n",
            "[7,   500] loss : 2.729\n",
            "[7,   500] val loss: 2.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [01:13<03:51, 10.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 7...\n",
            "[8,   500] loss : 2.717\n",
            "[8,   500] val loss: 2.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [01:24<03:46, 10.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 8...\n",
            "[9,   500] loss : 2.617\n",
            "[9,   500] val loss: 2.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [01:34<03:36, 10.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 9...\n",
            "[10,   500] loss : 2.543\n",
            "[10,   500] val loss: 2.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [01:49<03:54, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 10...\n",
            "[11,   500] loss : 2.478\n",
            "[11,   500] val loss: 2.555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [01:59<03:34, 11.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 11...\n",
            "[12,   500] loss : 2.418\n",
            "[12,   500] val loss: 2.462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 12/30 [02:09<03:15, 10.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 12...\n",
            "[13,   500] loss : 2.332\n",
            "[13,   500] val loss: 2.474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 13/30 [02:19<02:59, 10.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 13...\n",
            "[14,   500] loss : 2.249\n",
            "[14,   500] val loss: 2.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 14/30 [02:29<02:46, 10.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 14...\n",
            "[15,   500] loss : 2.161\n",
            "[15,   500] val loss: 2.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 15/30 [02:39<02:36, 10.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 15...\n",
            "[16,   500] loss : 2.116\n",
            "[16,   500] val loss: 2.408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 16/30 [02:50<02:25, 10.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 16...\n",
            "[17,   500] loss : 2.011\n",
            "[17,   500] val loss: 2.368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 17/30 [02:59<02:12, 10.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 17...\n",
            "[18,   500] loss : 1.949\n",
            "[18,   500] val loss: 2.306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 18/30 [03:10<02:02, 10.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 18...\n",
            "[19,   500] loss : 1.860\n",
            "[19,   500] val loss: 2.369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 19/30 [03:20<01:52, 10.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 19...\n",
            "[20,   500] loss : 1.777\n",
            "[20,   500] val loss: 2.310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 20/30 [03:30<01:41, 10.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 20...\n",
            "[21,   500] loss : 1.689\n",
            "[21,   500] val loss: 2.283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 21/30 [03:40<01:30, 10.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 21...\n",
            "[22,   500] loss : 1.603\n",
            "[22,   500] val loss: 2.373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 22/30 [03:50<01:20, 10.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 22...\n",
            "[23,   500] loss : 1.519\n",
            "[23,   500] val loss: 2.378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 23/30 [04:00<01:10, 10.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 23...\n",
            "[24,   500] loss : 1.476\n",
            "[24,   500] val loss: 2.382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 24/30 [04:10<00:59,  9.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 24...\n",
            "[25,   500] loss : 1.378\n",
            "[25,   500] val loss: 2.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 25/30 [04:19<00:49,  9.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 25...\n",
            "[26,   500] loss : 1.286\n",
            "[26,   500] val loss: 2.361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 26/30 [04:30<00:39,  9.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 26...\n",
            "[27,   500] loss : 1.221\n",
            "[27,   500] val loss: 2.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 27/30 [04:40<00:30, 10.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 27...\n",
            "[28,   500] loss : 1.193\n",
            "[28,   500] val loss: 2.399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 28/30 [04:49<00:19,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 28...\n",
            "[29,   500] loss : 1.101\n",
            "[29,   500] val loss: 2.493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 29/30 [04:59<00:09,  9.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 29...\n",
            "[30,   500] loss : 1.062\n",
            "[30,   500] val loss: 2.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [05:09<00:00, 10.33s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41414ba788894e01bcf19e578e3fb2c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇██▆▇▅▆▇▆▇▄▆▆▄▄▄▃▃▆▃▄▃▃▄▂▁▃▁▁▁</td></tr><tr><td>val loss</td><td>█▆▆▅▅▄▅▄▃▃▃▂▂▂▂▂▂▁▂▁▁▂▂▂▁▂▂▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.99176</td></tr><tr><td>val loss</td><td>555.07642</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">youthful-cosmos-10</strong> at: <a href='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer/runs/2puusksh' target=\"_blank\">https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer/runs/2puusksh</a><br/> View project at: <a href='https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer' target=\"_blank\">https://wandb.ai/dkkim2008-hankuk-university-for-foreign-studies/ast%20transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240819_120452-2puusksh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished training ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "Nc27d83X7mzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, X_test, y_test, device):\n",
        "  model.eval() #평가모드\n",
        "  inputs = X_test #앞쪽에서 만든 테스트용 데이터와 라벨\n",
        "  labels = y_test\n",
        "\n",
        "  with torch.no_grad():\n",
        "      inputs = torch.FloatTensor(inputs).to(device)  # (#data, #dim, #timesteps)\n",
        "      labels = torch.FloatTensor(labels).to(device)  # (#data, #labels)\n",
        "      utputs = model(inputs)\n",
        "      preds = torch.argmax(outputs, dim=1)\n",
        "      labels = torch.argmax(labels)\n",
        "  return np.array(preds.cpu()), np.array(labels.cpu())\n"
      ],
      "metadata": {
        "id": "CQ8Swi_86ITS"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}